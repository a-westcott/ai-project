from player import State, ALL, MOVE
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict as dd
from features import Î¦, ALL_STACKS, RINGS

INF = 99.0
TRAIN_DEPTH = 2

num_features = len(Î¦(State()))

def H(features, Î¸):
    h = np.dot(features, Î¸)
    if h > 0.99*INF:
        return 0.99*INF
    if h < -0.99*INF:
        return -0.99*INF
    return h

Î± = 0.00001
Î» = 0.5
MAX_CHANGE = 0.1
def tree_strap_train(Î¸o, Î¸m, Î¸e, depth=TRAIN_DEPTH, tdl=False):
    OPN, MID, END = 0, 1, 2
    state = State()
    random_turns = np.random.choice([0] + [2]*2 + [4]*4 + [8]*8 + 16*[16] + 32*[32])
    while (not state.terminal_test()):
        print(f'Turn number {state.turn}')
        print(state)
        print()

        if state.board[state.board > 0].sum() == 12:
            Î¸ = Î¸o
        elif state.board[state.board > 0].sum() > 5: 
            Î¸ = Î¸m
        else:
            Î¸ = Î¸e

        state.history[state] += 1

        if state.turn < random_turns:
            num_actions = len(state.actions(False))
            state = state.result(state.actions(False)[np.random.choice([i for i in range(num_actions)])])
        else:
            searched_states = []
            if tdl:
                V = negamax(State(state.board), -INF, INF, depth, Î¸)
                features = Î¦(state)
                searched_states = [(State(state.board), V, H(features, Î¸), features, depth)]
            else:
                V = minimax(State(state.board), depth, Î¸, searched_states)

            Î”Î¸ = np.zeros(num_features)
            for s, vs, hs, features, d in searched_states:
                #ð›¿ = V(s) - H(features, Î¸)
                ð›¿ = vs - hs
                Î”Î¸ += Î±*ð›¿*features*Î»**(depth-d)
                #s.board *= -1
                #flipped_features = Î¦(s)
                #ð›¿ = -(vs - hs) THIS IS ALL WRONG BTW, RECALCULATE V AND H
                #Î”Î¸ += Î±*ð›¿*flipped_features*Î»**(depth-d)
            
            for i in range(num_features):
                if Î”Î¸[i] > MAX_CHANGE:
                    Î”Î¸[i] = MAX_CHANGE
                elif Î”Î¸[i] < -MAX_CHANGE:
                    Î”Î¸[i] = -MAX_CHANGE
            Î¸ += Î”Î¸

            actions = []
            actions2 = []
            for a in state.actions():
                child = state.result(a)
                actions.append((-negamax(State(-1*child.board), -INF, INF, depth-1, Î¸), a))
                
            state = state.result(max(actions)[1])

        state.board *= -1
        state.turn += 1
    return Î¸o, Î¸m, Î¸e

def minimax(state, depth, Î¸, searched_states=None):
    if state.terminal_test():
        return state.utility()
    if depth == 0:
        return H(Î¦(state), Î¸)

    maxEval = -INF
    for a in state.actions():
        child = state.result(a)
        maxEval = max(maxEval, -minimax(State(-1*child.board), depth-1, Î¸, searched_states))
    
    if searched_states is not None:
        # Store the state, it's V(s) and H(s)
        features = Î¦(state)
        searched_states.append((state, maxEval, H(features, Î¸), features, depth))
    return maxEval


def negamax(state, alpha, beta, depth, Î¸):
    if state.terminal_test():
        return state.utility()
    if depth == 0:
        return H(Î¦(state), Î¸)

    v = -INF
    for a in state.actions():
        child = state.result(a)
        # game state must be flipped
        v = max(v, -negamax(State(-1*child.board), alpha, beta, depth-1, Î¸))
        if v >= beta:
            return v
        alpha = max(alpha, v)
    return v

def negamax2(state, depth, Î¸):
    """Search game to determine best action; use alpha-beta pruning.
    This version cuts off search and uses an evaluation function."""

    # Functions used by alpha_beta
    def max_value(state, alpha, beta, depth):
        if state.terminal_test():
            return state.utility()
        if depth == 0:
            return H(Î¦(state), Î¸)

        v = -INF
        for a in state.actions():
            child = state.result(a)
            # game state must be flipped
            v = max(v, -max_value(State(-1*child.board), best_score, beta, depth-1))
            if v >= beta:
                return v
            alpha = max(alpha, v)
        return v

    # Body of alpha_beta_cutoff_search starts here:
    # The default test cuts off at depth d or at a terminal state
    best_score = v = -INF
    beta = +INF
    best_action = None
    for a in state.actions():
        child = state.result(a)
        # game state must be flipped
        v = max(v, -max_value(State(-1*child.board), best_score, beta, depth-1))
        if v > best_score:
            best_score = v
            best_action = a
    return best_action

N_GAMES = 3
def main():
    Î¸o = np.random.uniform(-0.01, 0.01, num_features)
    Î¸m = np.random.uniform(-0.01, 0.01, num_features)
    Î¸e = np.random.uniform(-0.01, 0.01, num_features)

    Î¸o = np.zeros(num_features)
    Î¸m = np.zeros(num_features)
    Î¸e = np.zeros(num_features)

    Î¸os, Î¸ms, Î¸es = [np.copy(Î¸o)], [np.copy(Î¸m)], [np.copy(Î¸e)]
    for _ in range(N_GAMES):
        print('Game #', _)
        Î¸o, Î¸m, Î¸e = tree_strap_train(Î¸o, Î¸m, Î¸e, depth=TRAIN_DEPTH, tdl=False)
        Î¸os.append(np.copy(Î¸o))
        Î¸ms.append(np.copy(Î¸m))
        Î¸es.append(np.copy(Î¸e))
        
    cmap = sns.diverging_palette(10, 133, as_cmap=True)
    fig = plt.figure(figsize=(20, 4))
    FACTOR=1
    plt.subplot(3, 1, 1); sns.heatmap([Î¸o], cmap=cmap, vmin=-FACTOR, vmax=FACTOR, xticklabels=[])
    plt.subplot(3, 1, 2); sns.heatmap([Î¸m], cmap=cmap, vmin=-FACTOR, vmax=FACTOR, xticklabels=[])
    plt.subplot(3, 1, 3); sns.heatmap([Î¸e], cmap=cmap, vmin=-FACTOR, vmax=FACTOR, xticklabels=[])
    plt.savefig('Unlabelled-Heatmap.png')
    

    fig = plt.figure(figsize=(20, 20))
    plt.subplot(3, 1, 1)
    for i in range(len(Î¸o)):
        x = [j for j in range(len(Î¸os))]
        y = [Î¸os[j][i] for j in range(len(Î¸os))]
        plt.plot(x, y)
        plt.title('Opening', fontsize=16)
        plt.ylabel('Weight', fontsize=14)
    sns.despine()

    plt.subplot(3, 1, 2)
    for i in range(len(Î¸m)):
        x = [j for j in range(len(Î¸ms))]
        y = [Î¸ms[j][i] for j in range(len(Î¸ms))]
        plt.plot(x, y)
        plt.title('Mid-Game', fontsize=16)
        plt.ylabel('Weight', fontsize=14)
    sns.despine()

    plt.subplot(3, 1, 3)
    for i in range(len(Î¸e)):
        x = [j for j in range(len(Î¸es))]
        y = [Î¸es[j][i] for j in range(len(Î¸es))]
        plt.plot(x, y)
        plt.title('Ending', fontsize=16)
        plt.ylabel('Weight', fontsize=14)
        plt.xlabel('Game', fontsize=14)
    sns.despine()
    plt.savefig('Training.png')

    lbls = []
    fig = plt.figure(figsize=(4, 40))
    plt.subplot(1, 3, 1); sns.heatmap([[e] for e in Î¸o], cmap=cmap, vmin=-FACTOR, vmax=FACTOR, yticklabels=lbls, xticklabels=[])
    plt.subplot(1, 3, 2); sns.heatmap([[e] for e in Î¸m], cmap=cmap, vmin=-FACTOR, vmax=FACTOR, yticklabels=[], xticklabels=[])
    plt.subplot(1, 3, 3); sns.heatmap([[e] for e in Î¸e], cmap=cmap, vmin=-FACTOR, vmax=FACTOR, yticklabels=[], xticklabels=[])
    plt.savefig('Labelled-Heatmap.png')
    

if __name__ == '__main__':
    main()